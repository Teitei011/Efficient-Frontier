{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import investpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "import scipy.optimize as sco\n",
    "import scipy.interpolate as sci\n",
    "from pandas_datareader import data as web\n",
    "import warnings\n",
    "import time\n",
    "import seaborn as sn\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# plt.style.use('fivethirtyeight')\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"AcoesBrasileiras.txt\", \"r\")\n",
    "symbols = list(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = time.time()\n",
    "\n",
    "# Select Dates\n",
    "from_date = '01/01/2014'\n",
    "to_date = datetime.today().strftime('%d/%m/%Y') # Today\n",
    "\n",
    "# Get all stocks in one DF\n",
    "data = []\n",
    "new_symbols = [] \n",
    "\n",
    "for i in symbols:\n",
    "    try:\n",
    "        data.append(investpy.get_stock_historical_data(\n",
    "                                             stock=i,\n",
    "                                             country='brazil',\n",
    "                                             from_date=from_date, \n",
    "                                             to_date=to_date, \n",
    "                                             interval='Daily'))\n",
    "        new_symbols.append(i)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"It took {:.2f} seconds\".format(time.time() - initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stocks = Number of Dataframes !!\n",
    "dataf = [data[i] for i in range(len(new_symbols))] \n",
    "\n",
    "# Concatenate all stocks data\n",
    "df = pd.concat(objs = dataf,axis = 1)\n",
    "columns = [['Open_' + str(i) ,'High_' + str(i), 'Low_' + str(i), str(i), 'Volume_' + str(i) ,'Curreny_' + str(i)] for i in symbols]\n",
    "\n",
    "# Convert columns list into a flat list \n",
    "col = [ii for i in columns for ii in i]\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# # Rename columns in DF\n",
    "df.columns = col\n",
    "\n",
    "# # Select Price Column for each stock \n",
    "close_price = [i for i in symbols]\n",
    "df = df[close_price]\n",
    "df.to_csv('brazilian_stocks.csv') \n",
    "# dg = df\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"brazilian_stocks.csv\", parse_dates=True,\n",
    "#                  verbose=True)\n",
    " \n",
    "df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.head\n",
    "# for code in symbols:\n",
    "#       df[code] = pd.to_numeric(df[code], downcast='float')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Log Return\n",
    "log_ret = np.log(df/df.shift(1))\n",
    "log_ret.dropna(inplace=True)\n",
    "\n",
    "# Simple Return\n",
    "simple_ret = df.pct_change()\n",
    "simple_ret.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Volatility Function\n",
    "def realized_volatility(x):\n",
    "    return np.sqrt(np.sum(x**2))\n",
    "\n",
    "# Resample Data and Apply Function\n",
    "freq= 'D'\n",
    "n_days = 252\n",
    "r_vol = log_ret.groupby(pd.Grouper(freq=freq)).apply(realized_volatility) # set frequency\n",
    "r_vol = r_vol*np.sqrt(n_days) # change window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "def print_statistics(a1):\n",
    "  \n",
    "    sta1 = scs.describe(a1)\n",
    "\n",
    "    print('%14s %14s' % ('statistic','value')) \n",
    "    print(45*\"-\") \n",
    "    print('%14s %14.3f' % ('size',sta1[0])) \n",
    "    print('%14s %14.3f' % ('min',sta1[1][0])) \n",
    "    print('%14s %14.3f' % ('max',sta1[1][1]))\n",
    "    print('%14s %14.3f' % ('mean',sta1[2]))  \n",
    "    print('%14s %14.3f' % ('std',np.sqrt(sta1[3])))\n",
    "    print('%14s %14.3f' % ('skew',sta1[4])) \n",
    "    print('%14s %14.3f' % ('kurtosis',sta1[5])) \n",
    "\n",
    "# Normatity Test\n",
    "def normality_tests(arr):\n",
    "\n",
    "    print(\"Skew of data set  %14.3f\" % scs.skew(arr))\n",
    "    print(\"Skew test p-value %14.3f\" % scs.skewtest(arr)[1])\n",
    "    print(\"Kurt of data set  %14.3f\" % scs.kurtosis(arr))\n",
    "    print(\"Kurt test p-value %14.3f\" % scs.kurtosistest(arr)[1])\n",
    "    print(\"Norm test p-value %14.3f\" % scs.normaltest(arr)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Simple Return\n",
    "returns_annual = simple_ret.mean() * n_days\n",
    "\n",
    "# covariance\n",
    "cov_daily = simple_ret.cov()\n",
    "cov_annual = cov_daily * n_days\n",
    "\n",
    "# empty lists to store returns, volatility and weights of imiginary portfolios\n",
    "port_returns = []\n",
    "port_volatility = []\n",
    "sharpe_ratio = []\n",
    "stock_weights = []\n",
    "\n",
    "# number of combinations for imaginary portfolios\n",
    "num_stocks = len(symbols)\n",
    "num_portfolios = 10**6\n",
    "\n",
    "# set random seed for reproduction\n",
    "np.random.seed(42)\n",
    "\n",
    "# populate the empty lists with each portfolios returns,risk and weights\n",
    "for single_portfolio in range(num_portfolios):\n",
    "\n",
    "    weights = np.random.random(num_stocks)\n",
    "    weights /= np.sum(weights)\n",
    "    returns = np.dot(weights, returns_annual)\n",
    "    volatility = np.sqrt(np.dot(weights.T, np.dot(cov_annual, weights)))\n",
    "    sharpe = returns / volatility # riskfree = 0\n",
    "    sharpe_ratio.append(sharpe) \n",
    "    port_returns.append(returns)\n",
    "    port_volatility.append(volatility)\n",
    "    stock_weights.append(weights)\n",
    "\n",
    "# a dictionary for Returns and Risk values of each portfolio\n",
    "portfolio = {'Returns': port_returns,\n",
    "             'Volatility': port_volatility,\n",
    "             'Sharpe Ratio': sharpe_ratio}\n",
    "\n",
    "# extend original dictionary to accomodate each stock and weight in the portfolio\n",
    "for counter,symbol in enumerate(symbols):\n",
    "    portfolio[symbol+' Weight'] = [Weight[counter] for Weight in stock_weights]\n",
    "\n",
    "\n",
    "print(f\"It took {time.time() - start} seconds\")\n",
    "    \n",
    "portfolio.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make a nice dataframe of the extended dictionary\n",
    "dfm = pd.DataFrame(portfolio)\n",
    "\n",
    "# find min Volatility & max sharpe values in the dataframe (df)\n",
    "min_volatility = dfm['Volatility'].min()\n",
    "max_sharpe = dfm['Sharpe Ratio'].max()\n",
    "\n",
    "# use the min, max values to locate and create the two special portfolios\n",
    "sharpe_portfolio = dfm.loc[dfm['Sharpe Ratio'] == max_sharpe]\n",
    "min_variance_port = dfm.loc[dfm['Volatility'] == min_volatility]\n",
    "\n",
    "# plotting frontier\n",
    "fig,ax1=plt.subplots()\n",
    "dfm.plot.scatter('Volatility', 'Returns', c='Sharpe Ratio', \n",
    "                cmap='RdYlBu', figsize=(10, 8), grid=True,ax=ax1)\n",
    "plt.scatter(x=sharpe_portfolio['Volatility'], y=sharpe_portfolio['Returns'], marker=(5,1,0), c='y',s=500)\n",
    "plt.scatter(x=min_variance_port['Volatility'], y=min_variance_port['Returns'], marker=(5,1,0), c='r', s=500 )\n",
    "plt.xlabel('Volatility (Std. Deviation)')\n",
    "plt.ylabel('Expected Returns')\n",
    "plt.title('Efficient Frontier',fontsize=20)\n",
    "plt.show()\n",
    "plt.savefig(\"Efficient_Frontier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Minimun Variance Portfolio:\\n')\n",
    "min_volatility = dfm['Volatility'].min()\n",
    "min_variance_port = dfm.loc[dfm['Volatility'] == min_volatility]\n",
    "\n",
    "# print(type(min_variance_port))\n",
    " \n",
    "# min_variance_port.sort_values(by=['Brand'], inplace=True)\n",
    "\n",
    "# variance_result.write('Minimun Variance Portfolio:\\n')\n",
    "\n",
    "# min_variance_port1 = min_variance_port1.to_numpy()\n",
    "\n",
    "print(min_variance_port.T)\n",
    "# min_variance_port1 = min_variance_port1.sort()\n",
    "# min_variance_port1.savetxt('minimum_variance_portifolio.txt') \n",
    "\n",
    "#\n",
    "array = min_variance_port.to_numpy()\n",
    "\n",
    "file = open(\"minimum_variance_portifolio.txt\", \"w\")\n",
    "buffer = \"Returns: \"  +     str(array[0][0])   + \"\\nVolatility: \"  +    str(array[0][1]) + \"\\nSharpe Ratio: \"  +  str(array[0][2]) + \"\\n\"\n",
    "\n",
    "file.write(buffer)\n",
    "for i in range(len(symbols) - 1):\n",
    "    buffer =  str(symbols[i]) + \",\" + str(array[0][i + 3]) + \"\\n\"\n",
    "    file.write(buffer)\n",
    "file.close()     \n",
    "    \n",
    "# np.savetxt('minimum_variance_portifolio.txt', min_variance_port1.T)\n",
    "# for i in min_variance_port.iterrows(): \n",
    "#     variance_result.write(str(i) + \"\\n\")\n",
    "\n",
    "\n",
    "# print('\\n\\nMaximum sharpe Portfolio:\\n')\n",
    "# print(sharpe_portfolio.T)\n",
    "\n",
    "# variance_result.write('Maximum sharpe Portfolio:\\n')\n",
    "# for i in range(len(min_variance_port)):\n",
    "#     variance_result.write(min_variance_port[i].T + \"\\n\")\n",
    "    \n",
    "\n",
    "# variance_result.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Portfolio Calculations\n",
    "def statistics(weights):\n",
    "    ''' Sharpe ratio for riskfree = 0\n",
    "    '''\n",
    "    weights = np.array(weights)\n",
    "    p_rets = np.sum(simple_ret.mean() * weights) * n_days\n",
    "    p_volt = np.sqrt(np.dot(weights.T, np.dot(simple_ret.cov() * n_days, weights)))\n",
    "    return np.array([p_rets, p_volt, p_rets / p_volt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to Minimize\n",
    "def min_func_sharpe(weights):\n",
    "    return -statistics(weights)[2]\n",
    "\n",
    "def min_func_variance(weights):\n",
    "    return statistics(weights)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints\n",
    "cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x) - 1}) # No Short positions\n",
    "\n",
    "# Boundaries\n",
    "bnds = tuple((0, 1) for x in range(num_stocks))\n",
    "\n",
    "# Equal Weights\n",
    "equal_weights = num_stocks*[1./num_stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# # Maximization of Sharpe Ratio \n",
    "# opts = sco.minimize(min_func_sharpe, equal_weights, method='SLSQP',\n",
    "#                        bounds=bnds, constraints=cons)\n",
    "\n",
    "# print(\"It took {:.2f} seconds\".format(time.time() - start))\n",
    "# print(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Optimal weights that maximizes the sharpe ratio\n",
    "# pd.DataFrame([round(x,4) for x in opts['x']],index=symbols).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimal Portfolio Metrics [Annual Return, Annual Volatility, Sharpe Ratio]\n",
    "# statistics(opts['x']).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Minimun Variance Portfolio\n",
    "# start = time.time()\n",
    "\n",
    "# optv = sco.minimize(min_func_variance, equal_weights, method='SLSQP',\n",
    "#                        bounds=bnds, constraints=cons)\n",
    "\n",
    "# print(\"It took {:.2f} seconds\".format(time.time() - start))\n",
    "# optv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimal Weights in Minumum Variance Portfolio\n",
    "# pd.DataFrame([round(x,2) for x in optv['x']],index=symbols).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Minimum Variance Porfolio Metrics [Annual Return, Annual Volatility, Sharpe Ratio]\n",
    "# statistics(optv['x']).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eficient Frontier Calculations\n",
    "\n",
    "# cons = ({'type': 'eq', 'fun': lambda x:  statistics(x)[0] - i},\n",
    "#         {'type': 'eq', 'fun': lambda x:  np.sum(x) - 1})\n",
    "\n",
    "# bnds = tuple((0, 1) for x in weights)\n",
    "\n",
    "# target_ret = np.linspace(0.02, 0.142, 50)\n",
    "# target_vol = []\n",
    "\n",
    "# for i in target_ret:\n",
    "#     res = sco.minimize(min_func_variance, equal_weights, method='SLSQP',\n",
    "#                        bounds=bnds, constraints=cons)\n",
    "#     target_vol.append(res['fun'])\n",
    "\n",
    "# target_vol = np.array(target_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting frontier\n",
    "# fig,ax1=plt.subplots()\n",
    "# # Random Portfolio Composition\n",
    "# dfm.plot.scatter('Volatility', 'Returns', c='Sharpe Ratio', \n",
    "#                 cmap='RdYlBu', figsize=(10, 8), grid=True,ax=ax1)\n",
    "# # Eficient Frontier\n",
    "# plt.plot(target_vol, target_ret, c='black', lw=2, linestyle='--')\n",
    "# # portfolio with highest Sharpe ratio\n",
    "# # plt.plot(statistics(opts['x'])[1], statistics(opts['x'])[0], 'r*', markersize=28, c='y')    \n",
    "# # minimum variance portfolio\n",
    "# plt.plot(statistics(optv['x'])[1], statistics(optv['x'])[0], 'y*', markersize=28, c='r')\n",
    "\n",
    "# # Plot Stocks\n",
    "# MARKS = ['o', 'X', 'd', '*','x']\n",
    "\n",
    "# for i in range(num_stocks):\n",
    "#     plt.scatter(x=np.sqrt(cov_annual.iloc[i, i]),y=returns_annual[i],marker=MARKS[i],\n",
    "#              s=150, color='black', label=symbols[i])\n",
    "# plt.legend(loc = 'upper left')\n",
    "\n",
    "# plt.xlabel('Volatility (Std. Deviation)')\n",
    "# plt.ylabel('Expected Returns')\n",
    "# plt.title('Efficient Frontier',fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyportfolio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "# Portfolio Optimization\n",
    "\n",
    "mu = expected_returns.mean_historical_return(df)\n",
    "s = risk_models.sample_cov(df)\n",
    "\n",
    "# Optimize for max Sharpe Ratio\n",
    "\n",
    "ef = EfficientFrontier(mu,s)\n",
    "weights = ef.max_sharpe()\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights,'\\n')\n",
    "\n",
    "# Riskfree = 0\n",
    "ef.portfolio_performance(verbose=True, risk_free_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "total_position = 15000\n",
    "\n",
    "# Take the last price of stocks\n",
    "latest_prices = get_latest_prices(df)\n",
    "weights = cleaned_weights\n",
    "da = DiscreteAllocation(weights, latest_prices, total_portfolio_value = total_position)\n",
    "\n",
    "allocation, leftover = da.lp_portfolio()\n",
    "print(\"Discrete Allocation:\", allocation)\n",
    "print('Funds Remaining: ${:.2f}'.format(leftover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"It took {:.2f} seconds\" .format(time.time() - initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
